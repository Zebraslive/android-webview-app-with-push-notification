{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Train your own GAN in a few lines of code!\nSee original StyleGAN2 ADA github repo here: https://github.com/NVlabs/stylegan2-ada-pytorch\n\nBy using a pre-trained model along with data heavy data augmentation, we can train our own GAN with a very limited dataset (<1000 images). \n\nMake sure you have a GPU runtime!","metadata":{}},{"cell_type":"code","source":"!pip install pyspng ninja imageio-ffmpeg==0.4.3\n!git clone https://github.com/NVlabs/stylegan2-ada-pytorch\n!pip install gdown \n%cd /kaggle/working/stylegan2-ada-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-01-08T06:22:36.122755Z","iopub.execute_input":"2023-01-08T06:22:36.123034Z","iopub.status.idle":"2023-01-08T06:23:00.845199Z","shell.execute_reply.started":"2023-01-08T06:22:36.123004Z","shell.execute_reply":"2023-01-08T06:23:00.844267Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\nCollecting pyspng\n  Downloading pyspng-0.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n     |████████████████████████████████| 207 kB 2.1 MB/s            \n\u001b[?25hCollecting ninja\n  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n     |████████████████████████████████| 145 kB 23.9 MB/s            \n\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n     |████████████████████████████████| 26.9 MB 26.6 MB/s            \n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pyspng) (1.20.3)\nInstalling collected packages: pyspng, ninja, imageio-ffmpeg\nSuccessfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1 pyspng-0.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCloning into 'stylegan2-ada-pytorch'...\nremote: Enumerating objects: 128, done.\u001b[K\nremote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\nReceiving objects: 100% (128/128), 1.12 MiB | 7.50 MiB/s, done.\nResolving deltas: 100% (57/57), done.\nLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\nCollecting gdown\n  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.62.3)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.26.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.4.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.1)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n/kaggle/working/stylegan2-ada-pytorch\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/\n!git clone https://github.com/stylegan-human/StyleGAN-Human\n!wget 'https://cdn-lfs.huggingface.co/repos/1a/8c/1a8c83e1fa088d576d8201186ec45a38de5bcc3dfdbafcea86e5b3afa9362d1b/7af33f638e3b3aba7bf99456eec3e9d4a022d8a7dd67683a3605a7dd37665a3b?response-content-disposition=attachment%3B%20filename%3D%22stylegan_human_v2_512.pkl%22&Expires=1673415751&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzFhLzhjLzFhOGM4M2UxZmEwODhkNTc2ZDgyMDExODZlYzQ1YTM4ZGU1YmNjM2RmZGJhZmNlYTg2ZTViM2FmYTkzNjJkMWIvN2FmMzNmNjM4ZTNiM2FiYTdiZjk5NDU2ZWVjM2U5ZDRhMDIyZDhhN2RkNjc2ODNhMzYwNWE3ZGQzNzY2NWEzYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnN0eWxlZ2FuX2h1bWFuX3YyXzUxMi5wa2wlMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NzM0MTU3NTF9fX1dfQ__&Signature=dHvc7yaTAUB5NtA1vwnogSn4LXxufWERMQ4HJviNMs-VF-ZhzDTdGGIKC7m10yvRnL1QyIALkiIc~4JJMBiQS1Q0ghzM5ai3bNBnUOiiKkw~ZLNpoy3~4B3SXly5tgF8qZKDHkirna5IFyvLLd~mAbpubhGC1MSoHdv5spYQE4DSbyPFWRjz6LAz4Qp9TzGMN~s93gMi-eGA08DttzNXGT4n7G4RQl0YMJvcc-vVoBW7OjlS8yIAZpAlE~05bGQY9p8ECviHFz-FCQJ5TKn4NbCrtAKoXsRz9OjTtIXczD7Jg4oNIW9qXq3vZIAg~awElidutrX925BeP5zuTjIZRg__&Key-Pair-Id=KVTP0A1DKRTAX' -O /kaggle/working/styleganhuman.pkl","metadata":{"execution":{"iopub.status.busy":"2023-01-08T05:45:05.025917Z","iopub.execute_input":"2023-01-08T05:45:05.026774Z","iopub.status.idle":"2023-01-08T05:45:23.190615Z","shell.execute_reply.started":"2023-01-08T05:45:05.026734Z","shell.execute_reply":"2023-01-08T05:45:23.189727Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'StyleGAN-Human'...\nremote: Enumerating objects: 342, done.\u001b[K\nremote: Counting objects: 100% (164/164), done.\u001b[K\nremote: Compressing objects: 100% (134/134), done.\u001b[K\nremote: Total 342 (delta 52), reused 121 (delta 27), pack-reused 178\u001b[K\nReceiving objects: 100% (342/342), 73.11 MiB | 37.72 MiB/s, done.\nResolving deltas: 100% (93/93), done.\n--2023-01-08 05:45:10--  https://cdn-lfs.huggingface.co/repos/1a/8c/1a8c83e1fa088d576d8201186ec45a38de5bcc3dfdbafcea86e5b3afa9362d1b/7af33f638e3b3aba7bf99456eec3e9d4a022d8a7dd67683a3605a7dd37665a3b?response-content-disposition=attachment%3B%20filename%3D%22stylegan_human_v2_512.pkl%22&Expires=1673415751&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzFhLzhjLzFhOGM4M2UxZmEwODhkNTc2ZDgyMDExODZlYzQ1YTM4ZGU1YmNjM2RmZGJhZmNlYTg2ZTViM2FmYTkzNjJkMWIvN2FmMzNmNjM4ZTNiM2FiYTdiZjk5NDU2ZWVjM2U5ZDRhMDIyZDhhN2RkNjc2ODNhMzYwNWE3ZGQzNzY2NWEzYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnN0eWxlZ2FuX2h1bWFuX3YyXzUxMi5wa2wlMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NzM0MTU3NTF9fX1dfQ__&Signature=dHvc7yaTAUB5NtA1vwnogSn4LXxufWERMQ4HJviNMs-VF-ZhzDTdGGIKC7m10yvRnL1QyIALkiIc~4JJMBiQS1Q0ghzM5ai3bNBnUOiiKkw~ZLNpoy3~4B3SXly5tgF8qZKDHkirna5IFyvLLd~mAbpubhGC1MSoHdv5spYQE4DSbyPFWRjz6LAz4Qp9TzGMN~s93gMi-eGA08DttzNXGT4n7G4RQl0YMJvcc-vVoBW7OjlS8yIAZpAlE~05bGQY9p8ECviHFz-FCQJ5TKn4NbCrtAKoXsRz9OjTtIXczD7Jg4oNIW9qXq3vZIAg~awElidutrX925BeP5zuTjIZRg__&Key-Pair-Id=KVTP0A1DKRTAX\nResolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.156.60.37, 108.156.60.44, 108.156.60.112, ...\nConnecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.156.60.37|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 352745981 (336M) [binary/octet-stream]\nSaving to: ‘/kaggle/working/styleganhuman.pkl’\n\n/kaggle/working/sty 100%[===================>] 336.40M  30.0MB/s    in 12s     \n\n2023-01-08 05:45:23 (28.3 MB/s) - ‘/kaggle/working/styleganhuman.pkl’ saved [352745981/352745981]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp /kaggle/working/StyleGAN-Human/training_scripts/sg2/training/networks.py /kaggle/working/stylegan2-ada-pytorch/training/networks.py","metadata":{"execution":{"iopub.status.busy":"2023-01-08T06:25:52.620928Z","iopub.execute_input":"2023-01-08T06:25:52.621249Z","iopub.status.idle":"2023-01-08T06:25:53.606346Z","shell.execute_reply.started":"2023-01-08T06:25:52.621216Z","shell.execute_reply":"2023-01-08T06:25:53.605149Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/stylegan2-ada-pytorch/training","metadata":{"execution":{"iopub.status.busy":"2023-01-08T06:25:10.518555Z","iopub.execute_input":"2023-01-08T06:25:10.518856Z","iopub.status.idle":"2023-01-08T06:25:11.501685Z","shell.execute_reply.started":"2023-01-08T06:25:10.518823Z","shell.execute_reply":"2023-01-08T06:25:11.500803Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"__init__.py  augment.py  loss.py      training_loop.py\n__pycache__  dataset.py  networks.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!python trainh.py --outdir=training_results/sg2/ --metrics=None --data=/kaggle/input/croppedhumans --gpus=2 --aug=noaug --mirror=1 --snap=15 --cfg=shhq --square=False --resume=training_results/sg2/00003-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/network-snapshot-000000.pkl","metadata":{"execution":{"iopub.status.busy":"2023-01-08T14:11:05.586647Z","iopub.execute_input":"2023-01-08T14:11:05.586951Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"square :  False\ndesc:  croppedhumans\n\nTraining options:\n{\n  \"num_gpus\": 2,\n  \"image_snapshot_ticks\": 15,\n  \"network_snapshot_ticks\": 15,\n  \"metrics\": [],\n  \"random_seed\": 0,\n  \"training_set_kwargs\": {\n    \"class_name\": \"training.dataset.ImageFolderDataset\",\n    \"path\": \"/kaggle/input/croppedhumans\",\n    \"use_labels\": false,\n    \"max_size\": 63,\n    \"xflip\": true,\n    \"square\": false,\n    \"resolution\": 512\n  },\n  \"data_loader_kwargs\": {\n    \"pin_memory\": true,\n    \"num_workers\": 3,\n    \"prefetch_factor\": 2\n  },\n  \"G_kwargs\": {\n    \"class_name\": \"training.networks.Generator\",\n    \"z_dim\": 512,\n    \"w_dim\": 512,\n    \"mapping_kwargs\": {\n      \"num_layers\": 8\n    },\n    \"synthesis_kwargs\": {\n      \"channel_base\": 32768,\n      \"channel_max\": 512,\n      \"num_fp16_res\": 4,\n      \"conv_clamp\": 256\n    },\n    \"square\": false\n  },\n  \"D_kwargs\": {\n    \"class_name\": \"training.networks.Discriminator\",\n    \"block_kwargs\": {},\n    \"mapping_kwargs\": {},\n    \"epilogue_kwargs\": {\n      \"mbstd_group_size\": 4\n    },\n    \"square\": false,\n    \"channel_base\": 32768,\n    \"channel_max\": 512,\n    \"num_fp16_res\": 4,\n    \"conv_clamp\": 256\n  },\n  \"G_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"lr\": 0.0025,\n    \"betas\": [\n      0,\n      0.99\n    ],\n    \"eps\": 1e-08\n  },\n  \"D_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"lr\": 0.0025,\n    \"betas\": [\n      0,\n      0.99\n    ],\n    \"eps\": 1e-08\n  },\n  \"loss_kwargs\": {\n    \"class_name\": \"training.loss.StyleGAN2Loss\",\n    \"r1_gamma\": 3.2768\n  },\n  \"total_kimg\": 25000,\n  \"batch_size\": 16,\n  \"batch_gpu\": 8,\n  \"ema_kimg\": 5.0,\n  \"ema_rampup\": null,\n  \"resume_pkl\": \"training_results/sg2/00003-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/network-snapshot-000000.pkl\",\n  \"ada_kimg\": 100,\n  \"run_dir\": \"training_results/sg2/00004-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom\"\n}\n\nOutput directory:   training_results/sg2/00004-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom\nTraining data:      /kaggle/input/croppedhumans\nTraining duration:  25000 kimg\nNumber of GPUs:     2\nNumber of images:   63\nImage resolution:   512\nConditional model:  False\nDataset x-flips:    True\n\nCreating output directory...\nLaunching processes...\nLoading training set...\n/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n\nNum images:  126\nImage shape: [3, 512, 256]\nLabel shape: [0]\n\nConstructing networks...\nResuming from \"training_results/sg2/00003-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/network-snapshot-000000.pkl\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!curl -H \"Authorization: Bearer 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\" -X POST -F \"file=@/kaggle/working/stylegan2-ada-pytorch/training_results/sg2/00003-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/fakes000000.png\" -F \"repo_name=nudezStyleGANhuman\" https://huggingface.co/api/models/fattyflakie/nudezStyleGANhuman/upload/main/fakes000000.png","metadata":{"execution":{"iopub.status.busy":"2023-01-08T14:09:19.887908Z","iopub.execute_input":"2023-01-08T14:09:19.888198Z","iopub.status.idle":"2023-01-08T14:09:23.355179Z","shell.execute_reply.started":"2023-01-08T14:09:19.888166Z","shell.execute_reply":"2023-01-08T14:09:23.354313Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"{\"url\":\"https://huggingface.co/fattyflakie/nudezStyleGANhuman/blob/main/fakes000000.png\"}","output_type":"stream"}]},{"cell_type":"code","source":"!ls training_results/sg2/00003-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:51:25.192721Z","iopub.execute_input":"2023-01-08T13:51:25.195485Z","iopub.status.idle":"2023-01-08T13:51:26.246123Z","shell.execute_reply.started":"2023-01-08T13:51:25.195431Z","shell.execute_reply":"2023-01-08T13:51:26.245252Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"events.out.tfevents.1673185048.ed7275cfc09e.21759.0\nfakes000000.png\nfakes_init.png\nlog.txt\nnetwork-snapshot-000000.pkl\nreals.png\nstats.jsonl\ntraining_options.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preprocessing Dataset","metadata":{}},{"cell_type":"code","source":"!python dataset_tool.py --source=/kaggle/input/humanset --dest=./datasets/human.zip --width 512 --height 256","metadata":{"execution":{"iopub.status.busy":"2023-01-08T06:28:03.052415Z","iopub.execute_input":"2023-01-08T06:28:03.052715Z","iopub.status.idle":"2023-01-08T06:28:04.319592Z","shell.execute_reply.started":"2023-01-08T06:28:03.052681Z","shell.execute_reply":"2023-01-08T06:28:04.318465Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Usage: dataset_tool.py [OPTIONS]\nTry 'dataset_tool.py --help' for help.\n\nError: No such option: --square Did you mean --source?\n","output_type":"stream"}]},{"cell_type":"code","source":"!python train.py --help","metadata":{"execution":{"iopub.status.busy":"2022-02-19T20:22:47.038824Z","iopub.execute_input":"2022-02-19T20:22:47.039105Z","iopub.status.idle":"2022-02-19T20:22:49.890973Z","shell.execute_reply.started":"2022-02-19T20:22:47.039075Z","shell.execute_reply":"2022-02-19T20:22:49.890042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training will take a long time, make sure you have enough GPU hours available (minimum 10 hours required for good results)\nDo !python train.py --help to see the different optional arguments available.\n\nResume from your previous checkpoint of notebook times out. Get output model from: ./stylegan2-ada-pytorch/results","metadata":{}},{"cell_type":"code","source":"!python train.py --outdir ./results --snap=4 --gpus=2 --cfg=auto --data=./datasets/girls2.zip --augpipe=\"bg\" --mirror=True --metrics=None --resume=/kaggle/working/stylegan2-ada-pytorch/training_results/sg2/00000-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/network-snapshot-000048.pkl --augpipe=\"bg\" --kimg=145","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!cd /kaggle/working/stylegan2-ada-pytorch/results/00002-girls-mirror-paper512-kimg145-bg-resumecustom && zip -r /kaggle/working/output_images.zip . >/dev/null\n!curl --progress-bar --upload-file /kaggle/working/stylegan2-ada-pytorch/training_results/sg2/00002-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/fakes000104.png https://transfer.sh/fakes000104.png -H \"Max-Days: 1\"","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:30:27.719124Z","iopub.execute_input":"2023-01-08T13:30:27.719431Z","iopub.status.idle":"2023-01-08T13:30:38.291984Z","shell.execute_reply.started":"2023-01-08T13:30:27.719397Z","shell.execute_reply":"2023-01-08T13:30:38.290682Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"https://transfer.sh/Df6rvA/fakes000104.png","output_type":"stream"}]},{"cell_type":"code","source":"!curl --progress-bar --upload-file /kaggle/working/stylegan2-ada-pytorch/training_results/sg2/00001-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/network-snapshot-000080.pkl https://transfer.sh/network-snapshot-000080.pkl -H \"Max-Days: 5\"","metadata":{"execution":{"iopub.status.busy":"2023-01-08T10:23:49.871500Z","iopub.execute_input":"2023-01-08T10:23:49.871809Z","iopub.status.idle":"2023-01-08T10:53:01.220304Z","shell.execute_reply.started":"2023-01-08T10:23:49.871775Z","shell.execute_reply":"2023-01-08T10:53:01.219461Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"^C\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls /kaggle/working/stylegan2-ada-pytorch/training_results/sg2/00001-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/","metadata":{"execution":{"iopub.status.busy":"2023-01-08T10:06:07.671341Z","iopub.execute_input":"2023-01-08T10:06:07.671659Z","iopub.status.idle":"2023-01-08T10:06:08.638926Z","shell.execute_reply.started":"2023-01-08T10:06:07.671624Z","shell.execute_reply":"2023-01-08T10:06:08.637977Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"events.out.tfevents.1673164960.ed7275cfc09e.10622.0\nfakes000000.png\nfakes000008.png\nfakes000016.png\nfakes000024.png\nfakes000032.png\nfakes000040.png\nfakes000048.png\nfakes000056.png\nfakes000064.png\nfakes000072.png\nfakes000080.png\nfakes_init.png\nlog.txt\nnetwork-snapshot-000000.pkl\nnetwork-snapshot-000008.pkl\nnetwork-snapshot-000016.pkl\nnetwork-snapshot-000024.pkl\nnetwork-snapshot-000032.pkl\nnetwork-snapshot-000040.pkl\nnetwork-snapshot-000048.pkl\nnetwork-snapshot-000056.pkl\nnetwork-snapshot-000064.pkl\nnetwork-snapshot-000072.pkl\nnetwork-snapshot-000080.pkl\nreals.png\nstats.jsonl\ntraining_options.json\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm /kaggle/working/stylegan2-ada-pytorch/training_results/sg2/00002-croppedhumans-rectangle-mirror-shhq2-noaug-resumecustom/network-snapshot-000080.pkl","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:34:25.158304Z","iopub.execute_input":"2023-01-08T13:34:25.158951Z","iopub.status.idle":"2023-01-08T13:34:26.176523Z","shell.execute_reply.started":"2023-01-08T13:34:25.158912Z","shell.execute_reply":"2023-01-08T13:34:26.175503Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"Stopping training as example notebook","metadata":{}}]}